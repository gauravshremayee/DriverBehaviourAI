#!/usr/bin/env python
# coding: utf-8


import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from keras.utils import to_categorical

'''
Read the data from the csv file into a pandas DataFrame

Data Description:
    The columns contained in the data are:
    1. Time
    2. Epoch
    3. Electrode
    4. Attention
    5. Meditation
    6. Delta
    7. Theta
    8. Low Alpha
    9. High Alpha
    10. Low Beta
    11. High Beta
    12. Low Gamma
    13. Mid Gamma

    Columns 1-3 are meta data and is not actual data. These rows are not used
    by the machine learning algorithms.

    Columns 4-5 have been calculated after applying CNN (according to the flow
    chart given). These values are used to calculate the label of the data,
    i.e, if the driver is drowsy or awake. The logic used for this calculation
    is explained below.

    Columns 6-13 are the actual data. These are the waves of various frequency,
    collected by the electrode. Human brain gives out different kind of waves
    at different levels of attentiveness. These columns are used by machine
    learning algorithm to predict the state of the driver.
'''
data = pd.read_csv('eegsignals.csv')


'''
Take the relevant rows on which Machine Leaning algorithm will be applied
'''
dataRel = data.loc[:,'Delta':'Mid Gamma']
dataHeaders = list(dataRel.columns.values)
'''
Normalize the data. This changes the range of each column to be from 0 to 1.
'''
normData = preprocessing.normalize(dataRel)

'''
We are running the kmeans algorithm with the expected number of classes as 3.
This will categorize the normalized data into 3 classes based on distance. The
3 classes in our case are awake, drowsy and asleep. This data is used to
generate labels for the data.
'''
kmeans = KMeans(3).fit(normData)

'''
The labels generated by KMeans are saved as Result with the data. We will be
predicting these labels using the neural net.
'''
data['Result'] = kmeans.labels_

'''
We are deciding the name of the label based on the median value of Delta for
the clusters. We have the domain knowledge that an alert person has high values
for Delta.
'''
labels = {}
for i in range(3):
    if (np.min(data.loc[data["Result"] == i]["Delta"].values) > 110000):
        labels[i]="Alert"
    else:
        labels[i]="Sleepy"
'''
Split the dataset into train and test. 20% of data points are selected randomly
to be the part of the test case.
'''
X_Train, X_Test, Y_Train, Y_Test = train_test_split(normData, data['Result'], test_size=0.2)


'''
The labels generated for the data is changed to one hot form.

label 1 = [0, 0, 1]
label 2 = [0, 1, 0]
label 3 = [1, 0, 0]

This is the one hot representation of the data labels that we are using.
For any output only one index will have 1 and rest all will be zero. The index
will be representing the label of the data point.

This is done because the neural network being used to predict the state of the
driver will be generating data in one hot form.
'''
one_hot = to_categorical(data['Result'])
one_hot_train = to_categorical(Y_Train)
one_hot_test = to_categorical(Y_Test)


'''
We will be using a Sequential model. It consits of layers of neurons placed one
after another. The input is fed into the first layer, the output of the first
layer is connected to the input of the second layer and so on and so forth.

We will be using a three layerd neural network.

The first layer is a dense layer, this means that the output of each neuron will
be connected to all the neurons of the next layer. This layer acts at the
input layer.

The second layer is the hidden layer. This layer processes intermediate data
generated by the first layer. This data is generated by using complex formulas
and is beyond human interpretation. Fortunately we don't have to deal with this
data. This is fed into the output layer.

The last layer is an Activation or the output layer. It uses the sigmoid function
to give an output class representing the state of the driver. This layer has three
neurons and generates output on one hot form.
'''
modelNN = Sequential()

modelNN.add(Dense(8, input_dim=8, activation='relu'))

modelNN.add(Dense(8, activation='relu'))

modelNN.add(Dense(3, activation='sigmoid'))

'''
We compile the model using binary_crossentropy as the loss function. This is
used to calculate the deviation from actual output after every iteration. The
aim of the model is to minimize the value of this loss function. The deviation
after each iteration is backpropogated to adjust the values of the variables.
'''
modelNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

'''
Use the dataset to train the algorithm. epochs are the number of sweeps of the
data that we do.
'''
modelNN.fit(X_Train, one_hot_train, epochs=25)

print("Test Result:")

'''
Run the model that we trained above to predict the Result for the test points
and calculate the accuracy.
'''
print("Evaluating the model using test data")
res = modelNN.evaluate(X_Test, one_hot_test)
print(modelNN.metrics_names)
print(res)

'''
Print the data point, the actual class and the predicted class
'''
def output(data, pred, label):
    print(dataHeaders)
    for i in range(len(data)):
        print(str(data[i])+" correct: "+ labels[label[i]] +" Predicted: "+str(labels[np.argmax(pred[i])]))
        print()
def predict(data, label):
    data = data.loc[:, "Delta":"Mid Gamma"]
    normInput = preprocessing.normalize(data)
    pred = modelNN.predict(normInput)
    labelValue = list(labels.keys())[list(labels.values()).index(label)]
    actualLabels = [labelValue]*len(data.values)
    output(data.values,pred,actualLabels)
pred = modelNN.predict(X_Test)
#output(X_Test,pred,Y_Test.values)

print("reading alert_csvfile.csv")
inputData = pd.read_csv("relaxed_csvfile.csv")
predict(inputData,"Alert")

print("reading relaxed_csvfile.csv")
relaxedData = pd.read_csv("relaxed_csvfile.csv")
predict(relaxedData, "Sleepy")
